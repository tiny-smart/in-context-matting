cfg_feature_extractor:
  load_odise_params: False # True only if init_ckpt is sd-v1.3
  target: icm.models.feature_extractor.modeling.meta_arch.ldm.LdmImplicitCaptionerExtractor
  params:
    encoder_block_indices: []
    # 128*512*512 256*256*256 512*128*128 512*64*64
    unet_block_indices: [2, 5, 8, 11]
    # 2560*8*8 1920*16*16 960*32*32 640*64*64
    decoder_block_indices: []
    # 512*64*64 512*128*128 256*256*256 128*512*512
    steps: [0]
    
    feature_before_module: False # new, to get feature after unsample
    share_noise: False # new, to get N group features of samples

    learnable_time_embed: True
    num_timesteps: 1
    clip_model_name: "ViT-L-14-336"

    # set alpha, clip_project, time_embed_project require_grad=False
    freeze_all_params: True

    # diffusion-matte with sd://v2-1-base, odise with sd://v1-3"(init)
    init_checkpoint: "sd://v2-1-base"
    # if loading is slow, fix the clip model. /home/guohe/anaconda3/envs/icm/lib/python3.9/site-packages/ldm/modules/encoders/modules.py
    #                         and clip adaptor /data/guohe/diffusion-matting/ICM/icm/models/feature_extractor/modeling/meta_arch/clip.py

    # "sd://v1-3": ("v1-inference.yaml", (512, 512), (64, 64)),
    # "sd://v1-4": ("v1-inference.yaml", (512, 512), (64, 64)),
    # "sd://v1-5": ("v1-inference.yaml", (512, 512), (64, 64)),
    # "sd://v2-0-base": ("v2-inference.yaml", (512, 512), (64, 64)),
    # "sd://v2-0-v": ("v2-inference.yaml", (768, 768), (96, 96)),
    # "sd://v2-1-base": ("v2-inference.yaml", (512, 512), (64, 64)),
    # "sd://v2-1-v": ("v2-inference.yaml", (768, 768), (96, 96)),
    # "sd://x4-0-base": ("x4-upscaling.yaml", (2048, 2048), (512, 512)),

cfg_dataset:
  target: icm.data.data_generator.ContextDataset
  params:
    crop_size: 512 # new, same as dift
    phase: val
    norm_type: "sd" # new
    data:
      target: icm.data.image_file.ContextData
      params:
        ratio: 0.9
        dataset_name:
          ["PPM", "AM2k", "RWP636", "P3M_val_np"]

# cfg_dataset:
#   target: icm.data.data_generator.MultiDataGeneratorDoubleSet
#   params:
#     crop_size: 512
#     phase: val
#     data:
#       target: icm.data.image_file.MultiImageFileDoubleSet
#       params:
#         ratio: 0.9
#         dataset_name:
#           ["AIM", "PPM", "AM2k_train", "AM2k_val", "RWP636", "P3M_val_np"]