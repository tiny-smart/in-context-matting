model:
  target: icm.models.diffusion_matting.DiffusionMatting
  params:
    learning_rate: 0.0005
    guidance_type: "trimap" # 'coarse_map', 'trimap'

    cfg_loss_function:
      target: icm.models.criterion.loss_function.LossFunction
      params:
        losses: [
            "unknown_l1_loss",
            "known_l1_loss",
            "loss_pha_laplacian",
            "loss_gradient_penalty",
            # "smooth_l1_loss",
            # "cross_entropy_loss",
            # "focal_loss",
          ]

    cfg_scheduler:
      target: icm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [250] # NOTE 1 for resuming. use 250 if starting from scratch
        cycle_lengths: [10000000000000]
        f_start: [1.e-6]
        f_max: [1.]
        f_min: [1.]

    cfg_feature_extractor:
      load_odise_params: False # True only if init_ckpt is sd-v1.3
      target: icm.models.feature_extractor.modeling.meta_arch.ldm.LdmImplicitCaptionerExtractorUnetOnly
      params:
        feature_index: 6

        # LdmExtractor params
        encoder_block_indices: [1, 3, 5, 7]
        # 128*512*512 256*256*256 512*128*128 512*64*64
        unet_block_indices: [2, 5, 8, 11]
        # 2560*8*8 1920*16*16 960*32*32 640*64*64
        decoder_block_indices: [2, 5, 8, 11]
        # 512*64*64 512*128*128 256*256*256 128*512*512
        steps: [0] # 0 for odise, 261 for DIFT
        share_noise: True
        init_checkpoint: "sd://v2-1-base"
        extract_feature_inputted_to_layer: True # True: odise  False: DIFT

        # diffusion-matte with sd://v2-1-base, odise with sd://v1-3"(init)

        # "sd://v1-3": ("v1-inference.yaml", (512, 512), (64, 64)),
        # "sd://v1-4": ("v1-inference.yaml", (512, 512), (64, 64)),
        # "sd://v1-5": ("v1-inference.yaml", (512, 512), (64, 64)),
        # "sd://v2-0-base": ("v2-inference.yaml", (512, 512), (64, 64)),
        # "sd://v2-0-v": ("v2-inference.yaml", (768, 768), (96, 96)),
        # "sd://v2-1-base": ("v2-inference.yaml", (512, 512), (64, 64)),
        # "sd://v2-1-v": ("v2-inference.yaml", (768, 768), (96, 96)),
        # "sd://x4-0-base": ("x4-upscaling.yaml", (2048, 2048), (512, 512)),

    cfg_decoder:
      target: icm.models.decoder.detail_capture.DetailCapture
      params:
        ckpt: null
        in_chans: 960
        img_chans: 4
        convstream_out: [48, 96, 192]
        fusion_out: [256, 128, 64, 32]

data:
  target: icm.data.data_module.DataModuleFromConfig
  params:
    batch_size: 8
    num_workers: 4
    shuffle_train: False
    train:
      target: icm.data.data_generator.MultiDataGeneratorDoubleSet
      params:
        crop_size: 512
        phase: train
        norm_type: "imagenet" # "imagenet" or "sd"
        data:
          target: icm.data.image_file.MultiImageFileDoubleSet
          params:
            ratio: 1
            dataset_name:
              [
                # "AIM",
                # "PPM",
                # "AM2k_train",
                # "AM2k_val",
                # "RWP636",
                # "P3M_val_np",
                "RM1k",
                "AIM-ICM",
              ]
    validation:
      target: icm.data.data_generator.MultiDataGeneratorDoubleSet
      params:
        crop_size: 512
        phase: val
        norm_type: "imagenet" # "imagenet" or "sd"
        data:
          target: icm.data.image_file.MultiImageFileDoubleSet
          params:
            ratio: 0
            dataset_name:
              [
                # "AIM",
                # "PPM",
                # "AM2k_train",
                # "AM2k_val",
                # "RWP636",
                # "P3M_val_np",
                # "RM1k",
                "ICM+AIM",
              ]
trainer:
  accelerator: "ddp"
  gpus: 2
  max_epochs: 100000
  auto_select_gpus: False
  num_sanity_val_steps: 0
  plugins:
    target: pytorch_lightning.plugins.DDPPlugin
    params:
      find_unused_parameters: False
  # weights_summary: full

  cfg_logger:
    target: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    params:
      save_dir: logs # set in main.py
      default_hp_metric: False

  cfg_callbacks:
    modelcheckpoint:
      target: pytorch_lightning.callbacks.ModelCheckpoint
      params:
        monitor: epoch
        mode: max
        save_top_k: 1000
        every_n_epochs: 1
        # save_last: True
        # save_weights_only: False
        filename: "{epoch:02d}-{val/mse_all:.5f}-{val/mse_unknown:.5f}"
        auto_insert_metric_name: False
